---
layout: topicmodeling
title: TopicModeling
banner: "/assets/banners/topic4.png"
heading: 'Topic Modeling'
subheading: 'Which topics do we lisen to the most?'
---

<h2>Topic Modeling goal</h2>
<p>
The topic modelling part of this study aim to investigate what lyrics we actually listen to and fills our minds with when we play our favourite songs. 
  We want to research if some topics are more popular than others and if the topics depend on the genre. 
Our study begins by looking at the most frequence words and see if some patterns can be drawn. Frome there we continue investigating the topics by
  cleaning the text and reducing the vocabulary size. The topic modelling is done on the cleaned data to reveal topics within the songs. 
  In order to get an even deeper insight into the music industri we investigate each genre at a time to see if they have their own individual topics. 
  The goal is to understand the words we listen to and to discover if the topics and messages from the lyrics depends on our choice of genre.
  
</p>

<h2>Topic Modeling tool</h2>

<p>
 The study will use Latent DirichletAllocation (LDA) to perform topic modeling on the data.  
  The LDA model consists of two main procedures; generating topics and assigning topics to each text. 
  Each text will then be described by a distribution of topics and each topic can in turn be described by a distribution of words.
  
  A necessary step for all topic models is to reduce corpus dimensionality, i.e. the total number of unique words, as much as possible prior to model implementation.
  The main reason being that unnecessary words adds too much noise when finding meaningful patterns. 
  
  
</p>   

<h2>Frequency count befor cleaning</h2>
<p>
As a priliminary investigation we look at the most frequence words within all songs to investigate if some topics is revealed. <br> </p>

<p> Top 10 most common words in the dataset:<br></p>


<table>
  <colgroup>
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
  <tr>
     <th>Word</th>
    <td>I</td>
    <td>the</td> 
    <td>you</td>
    <td>a</td>
    <td>to</td>
        <td>my</td>
    <td>me</td>
    <td>and</td>
        <td>in</td>
    <td>it</td>
  </tr>
  <tr>
    <th>Count</th> 
    <td>3813</td>
    <td>3420</td> 
    <td>3015</td>
        <td>2082</td> 
    <td>1950</td>
        <td>1707</td>
        <td>1512</td> 
    <td>1300</td>
            <td>1234</td> 
    <td>1216</td>
  </tr>
</table>



It is clear that the frequenced words are stopwords without meaning. 

   A thorough text cleaning is needed  in order to ensure a qualified topic modeling performance.
.</p>

<h2>Text cleaning</h2>

<p>

  
  
The  aim  of  text  cleaning  is  to  significantly  reduce  corpus  dimensionality. 
  The  quality  of  the definitive topics is highly dependent on the quality of the input data for the model. 
  
  The lyrics will undergo four different cleaning steps in order to produce the input for the topic model.  
  Below an overview of the full cleaning process canbe seen and the resulting vocabulary size after having applied the different cleaning techniques.
</p>

<p style="text-align:center;">
  <img src="image/voc.png" width="700" hight="500" >                                      
</p>

<p>
Starting with the raw corpus of 12,647 unique words reduced to 2,810 words in the ultimate output yields a total word reduction of 78%.  <br>
The four procedural steps are to be explained:
</p>

<p> &nbsp;&nbsp; 1. Noice</p>
<p> 
First, a preliminary noise cleaning of the text data is carried out, in which all words are transformed into lowercase capitalization, 
  ordinary stop-words such as ”the”, ”have” and ”should” are removed along with non-alphabetic characters (!?,.). 
  It is followed by lemmatization to extract the dictionary form of all words. 


<p> &nbsp;&nbsp; 2. Rare and short words</p>
<p>
A simple but efficient text cleaning step in terms of vocabulary reduction, is to remove rare and short words. 
  All words that are only mentioned one time in the entire dataset of lyrics are deemed too unique and without importance, hence they are deleted. 
  The same applies to words of only one character. 
</p>

<p> &nbsp;&nbsp; 3. Only noun, verb and adj</p>
<p>
 All words that are not labeled ”noun”, ”verb” or "adj" are removed as it is expected that the nouns, verbs and adjectives carry most 
  information on the message of a song.
</p>

<p> &nbsp;&nbsp; 4. Meaningless words</p>
<p>
As the larst cleaning step we looked at the frequency words and removed words with no particulary meaning for the overall messages. This will help the model perform. 
</p>

<p>
The text cleaning of the lyrics is now finalized and unimportant words have been removed. The cleaned data is not 
 ready to be used as input for a topic model.  

</p>

<h2>Frequency count after cleaning</h2>

<p>
It is of interest to examine the most frequent terms after the cleaning to detecting if possible topics appears now. 
</p>

<p> Top 10 most common words after cleaning<br></p>

<table>
    <colgroup>
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
  <tr>
     <th>Word</th>
    <td>love</td>
    <td>nigga</td> 
    <td>baby</td>
    <td>bitch</td>
    <td>fuck</td>
        <td>life</td>
    <td>shit</td>
    <td>money</td>
        <td>good</td>
    <td>play</td>
  </tr>
  <tr>
    <th>Count</th> 
    <td>569</td>
    <td>400</td> 
    <td>327</td>
        <td>268</td> 
    <td>207</td>
        <td>203</td>
        <td>188</td> 
    <td>171</td>
            <td>166</td> 
    <td>159</td>
  </tr>
</table>

<p>
 As hoped the top frequency words for the cleaned data indicates and reveals some possible topics, both some romance, wealth and hate.
  </p>

<h2>Topic Modeling</h2>

<p>
   The topic model is implemented to generate topics and label each song with the most appropriate topic.
  Based on a measure of coherence,the model determines the most optimal number of topics to represent the data. <br></p>
  
  <p style="text-align:center;">
  <img src="image/cor.png" width="700" hight="500" >                                      
</p>
  
  <p>
  As per the coherence measure,n=6 topics yield the most optimal representation. 
   The LDA generated topics cn be seen below including relevant keywords and their respective average sentiment score. </p>

<table>
  <colgroup>
   <col width="22%" />
<col width="23%" />
<col width="20%" />
<col width="35%" />
</colgroup>
  <tr>
     <th>Topic</th>
<th>Keywords</th>
    <th>Sentiment score</th>
    <th>Number of songs</th>

  </tr>
  <tr>
    <td>(1) Violent gangster</td>
    <td>money, nigga, shit, hit</td> 
    <td>0.22</td>
    <td> <p>46  <br>(28% HipHop, 26% Rock, 24% Country, 13% RnB, 9% Pop)</p></td>

  </tr>
    <tr>
    <td>(2) Ups and downs in romance</td>
    <td>love, heart, pain, lose, try</td> 
    <td>0.21</td>
        <td><p>52 <br>(25% Country, 23% Pop, 23% Rock, 17% RnB, 12% HipHop)</p></td>

  </tr>
    <tr>
    <td>(3) Breaking rules</td>
    <td>bitch, cheat, play, fuck</td> 
    <td>0.10</td>
      <td><p>62<br>(48% HipHop, 23% RnB, 13% Pop, 13% Country, 5% Rock)</p></td>

  </tr>
    <tr>
    <td>(4) Life experience</td>
    <td>world, mine, fine, dream, die</td> 
    <td>0.58</td>
        <td><p>101<br>(31% Pop, 26% Rock, 22% RnB, 19% Country, 3%HipHop)</p></td>

  
</table>

<p>
  The table above shows that topic 3 is the most negative topic(lowest sentiment score) and topic 4 is the most positive(highest sentiment score). 
  This does allign with the keywords for each of the topics and the fact that topic 3 has the highest portion of hiphop songs which from the sentiment analysis was the genre with most negative songs. 
  Furthermore it can be seen that the largest topic is topic 4 which is also the most positive topic. 
  This alligns with the results from the sentiment analysis that showed mos positive songs within the music industri. 
</p>
  

<h2>Model evaluation</h2>


<p>
  To evaluate the topic model performance we have used the below interactive LDA visualizer. Wirth this tool we have examine how themodel generated the topics. 
  The chart to the left illustrate how separated the classes are
    whereas the chart to the right shows the words that reprsents the topics ordered by relevance. The left chart depends on the tunable λ-parameter. 
    The λ-parameter represents the TF-IDF adjustment, which assigns less importance to words with high frequency count,
   λ=1 corresponds to importance by term frequency. Decreasing the parameter yields less importance to more frequently used words.
</p>


{% include lda.html %}


<p>
 From the inteactive LDA visulaizer we discover that the four topic is nicely seperated, indicating that the cleaningprocess went well and the model has created some good topic to describe the data.
  
</p>

<p>
 Another way to evaluate the model performance is to look into some lyrics and evaluate if they have been classified correctly.  
  We do  this by taking a random sample of three songs and determine if  they match the topic class they were put in. 
  To see a more detailed model evaluation by sample of data points go to <a href="https://drive.google.com/drive/folders/121j5cVK8jS9F-RIRD84YaGZYDMvBw0IM?usp=sharing">The Explainer Notebook</a>.
</p>

<div class="row">
  <div class="column">
    <b> Too Good At Goodbyes by Sam Smith- Topic 2</b>
<p> It is a breakup song about getting used to being dumped and how previous experiences in  relationships makes him
  protect himself. This falls perfectly into the topic <i>"Ups and downs in romance"</i> and the songs is thereby perfectly classified. 
    </p>
  </div>
  <div class="column">
    <iframe src="https://open.spotify.com/embed/track/3VlbOrM6nYPprVvzBZllE5?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
    <p>Link to lyrics: <a href="https://genius.com/Sam-smith-too-good-at-goodbyes-lyrics">Too Good At Goodbyes</a></p>
  </div>
   </div>


<div class="row">
  <div class="column">
<b>That's what I like by Bruno Mars- Topic 4</b>
<p>This song is about the rich lifestyle with glammer and it is therefore fair to say that it fits the topic life experience. 

    </p>  
  </div>
  <div class="column">
    <iframe src="https://open.spotify.com/embed/track/0KKkJNfGyhkQ5aFogxQAPU?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
    <p>Link to lyrics:  <a href="https://genius.com/Bruno-mars-thats-what-i-like-lyrics">That's what I like</a></p></div>
   </div>



<div class="row">
  <div class="column">
    <b> Only by Nicki Minaj- Topic 3</b>
<p> It is an extremely sexistic song where Minaj defends herself for her sexual life. It is therefore no surprise that the model classifies this as topic 3.  
  
    </p>
  </div>
  <div class="column">
    <iframe src="https://open.spotify.com/embed/album/3uF3FOAnuhA5KJAoVJ4IuP?utm_source=generator&theme=0" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
    <p>Link to lyrics: <a href="https://genius.com/Nicki-minaj-only-lyrics">Only</a></p></div></div>




<h2>Wordclouds pr genre</h2>
<p>
The wordclouds below illustrates words within each topic. The size of the words represents their relative relevance.
</p>
<p style="text-align:center;">
  <img src="image/genreWC.png" width="1000" height="360">                                      
</p>

<p>
  ddd...
</p>

                                           
<h2>Topic Modeling conclusion</h2>

<p>
This study provides an understanding of what the words we listen to is all about. The topic model detected different topics within songs and examines which topics
  has the higest/lowest sentiment score indicating the emotional influence of the topic. Furthermore the results shows which topic has the highest reprsentstion and
  what genre the topics occurs mostly in. With this topic part of the study you are provided with a tool to understand what kind of music you should chose depending on the topic you want to listen to. 
</p>   
